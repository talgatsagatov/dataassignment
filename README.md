#### Olist Commerce Analytics â€” Assignment #1

Analytical project on the Brazilian e-commerce dataset Olist for a data visualization course.
The project includes: provisioning a PostgreSQL database, basic SQL checks, 10 analytical queries, a Python script to export results, and an optional Apache Superset dashboard.

Summary: 8 related tables, 500k+ rows in total; PostgreSQL import; SQL + Python (pandas/psycopg2); results exported to exports/; ER diagram and full reproducibility instructions.

#### Repository Structure

sql/
  schema_olist.sql                 # DB schema (PK/FK/indexes)
  import_olist.sql                 # CSV import (COPY)
  queries.sql                      # basic checks + 10 analytics
exports/
  monthly_revenue.csv              # generated by main.py
  payment_mix.csv                  # generated by main.py
  top_categories.csv               # generated by main.py
main.py                            # Python: connect to DB, run queries, export CSV
requirements.txt                   # pandas, psycopg2-binary
README.md                          # this file
dataset/                           

#### Dataset

Public Olist e-commerce dataset with 8 related tables:
orders (~99k), order_items (~113k), order_payments (~104k)
customers (~99k), sellers (~3k), products (~33k)
geolocation (~1,000k), product_category_name_translation (~71)

Place all CSV files into dataset/:
olist_orders_dataset.csv, olist_order_items_dataset.csv, olist_order_payments_dataset.csv
olist_customers_dataset.csv, olist_products_dataset.csv, olist_sellers_dataset.csv
olist_geolocation_dataset.csv, product_category_name_translation.csv

#### ER Diagram

erDiagram
  customers { TEXT customer_id PK
              TEXT customer_unique_id
              INT  customer_zip_code_prefix
              TEXT customer_city
              TEXT customer_state }
  sellers   { TEXT seller_id PK
              INT  seller_zip_code_prefix
              TEXT seller_city
              TEXT seller_state }
  geolocation { INT geolocation_zip_code_prefix
                FLOAT geolocation_lat
                FLOAT geolocation_lng
                TEXT geolocation_city
                TEXT geolocation_state }
  products  { TEXT product_id PK
              TEXT product_category_name
              INT  product_name_lenght
              INT  product_description_lenght
              INT  product_photos_qty
              INT  product_weight_g
              INT  product_length_cm
              INT  product_height_cm
              INT  product_width_cm }
  product_category_name_translation { TEXT product_category_name PK
                                     TEXT product_category_name_english }
  orders    { TEXT order_id PK
              TEXT customer_id FK
              TEXT order_status
              TIMESTAMP order_purchase_timestamp
              TIMESTAMP order_approved_at
              TIMESTAMP order_delivered_carrier_date
              TIMESTAMP order_delivered_customer_date
              TIMESTAMP order_estimated_delivery_date }
  order_items { TEXT order_id FK
                INT  order_item_id
                TEXT product_id FK
                TEXT seller_id FK
                TIMESTAMP shipping_limit_date
                NUMERIC price
                NUMERIC freight_value
                PK "order_id, order_item_id" }
  order_payments { TEXT order_id FK
                   INT  payment_sequential
                   TEXT payment_type
                   INT  payment_installments
                   NUMERIC payment_value
                   PK "order_id, payment_sequential" }

  orders ||--o{ order_items : contains
  orders ||--o{ order_payments : paid_by
  customers ||--o{ orders : places
  products ||--o{ order_items : appears_in
  sellers  ||--o{ order_items : fulfills

#### Quick Start

1) PostgreSQL: create DB and import CSVs

# Create database (if not yet created)
"C:\Program Files\PostgreSQL\18\bin\psql.exe" -U postgres -d postgres -c "CREATE DATABASE olistdb;"

# From the project root, run the import script
"C:\Program Files\PostgreSQL\18\bin\psql.exe" -U postgres -d olistdb -v ON_ERROR_STOP=1 -f "sql\import_olist.sql"

2) Python environment and CSV exports

python -m venv .venv
# If PowerShell blocks scripts:
Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass

.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt

$env:PGHOST="localhost"; $env:PGPORT="5432"
$env:PGUSER="postgres";  $env:PGPASSWORD="your_password"; $env:PGDATABASE="olistdb"

python .\main.py

# The script writes full results to exports/:
monthly_revenue.csv
payment_mix.csv
top_categories.csv

#### Basic Checks and 10 Analytics

File: sql/queries.sql

Basic checks (top lines of the file)

SELECT * ... LIMIT 10
WHERE ... ORDER BY ...
GROUP BY with COUNT/MIN/MAX
JOIN (orders + customers)

Run them together with:
\i 'sql/queries.sql'

Ten analytical queries

1. Monthly revenue (items price + freight_value), aggregated by purchase month.
2. Top-10 product categories by revenue (with English translation).
3. Top-10 cities by number of orders.
4. Average order value (AOV).
5. Payment mix by payment_type (counts and percentages).
6. Delivery speed by month (avg days from purchase to delivery).
7. Top-10 sellers by revenue.
8. Delivered vs. canceled orders distribution.
9. Average freight share in order value.
10. Fastest categories by delivery time (with a minimum observations threshold).

#### License
For educational use only. Data based on the public Olist dataset.

#### Links
Repository: https://github.com/talgatsagatov/dataassignment